{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limiting-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verified-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([5.], requires_grad = True)\n",
    "b = torch.tensor([6.], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-corps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excessive-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "copyrighted-mongolia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-scenario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = a**3 - b ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informative-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy/da = 3*a**2 = 75\n",
    "#dy/db = -2b = -12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certified-campbell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clear-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resident-toyota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "perceived-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-desert",
   "metadata": {},
   "source": [
    "- W and b are parameters, which we need to optimize.thus, we need to be able to compute the gradients of loss function with respect to those variables.\n",
    "- In order to do that, we set the required_grad = True for those tenosrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inappropriate-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(10,1, requires_grad = True)\n",
    "b = torch.randn(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metropolitan-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1248],\n",
       "        [-0.6565],\n",
       "        [-0.2815],\n",
       "        [-1.9687],\n",
       "        [ 0.8520],\n",
       "        [ 0.2365],\n",
       "        [ 0.5617],\n",
       "        [-0.1154],\n",
       "        [-0.4625],\n",
       "        [ 0.0360]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cubic-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5346], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "molecular-andorra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8039, 0.1727, 0.9479, 0.4151, 0.7902, 0.1132, 0.0360, 0.7497, 0.9182,\n",
       "         0.9580]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "female-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5842]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.matmul(x, w) + b #input * weights  + bias\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prospective-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5842]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the loss\n",
    "loss = 1 - output\n",
    "loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extra-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward propagation \n",
    "#Here we need to compute the derivatives of our loss function with respect to parameters, \n",
    "#we need dloss/ dw and dloss/ db under some fixed values of x and y.\n",
    "#To compute those derivatives, we call loss.backward() function.\n",
    "#then retrieve the values from w.grad and b.grad.\n",
    "loss.backward() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "romantic-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8039],\n",
       "        [-0.1727],\n",
       "        [-0.9479],\n",
       "        [-0.4151],\n",
       "        [-0.7902],\n",
       "        [-0.1132],\n",
       "        [-0.0360],\n",
       "        [-0.7497],\n",
       "        [-0.9182],\n",
       "        [-0.9580]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "appropriate-timer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-starter",
   "metadata": {},
   "source": [
    "- By default, all tensors with requires_grad=True are tracking their computational history and support gradient computation.\n",
    "- We can stop tracking computations by surrounding our computation code with torch.no_grad() block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "disturbed-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here updating weights \n",
    "#learning rate = 0.001 \n",
    "with torch.no_grad():\n",
    "    w = w - 0.001 * w.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "military-charity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1256],\n",
       "        [-0.6563],\n",
       "        [-0.2806],\n",
       "        [-1.9683],\n",
       "        [ 0.8527],\n",
       "        [ 0.2366],\n",
       "        [ 0.5618],\n",
       "        [-0.1146],\n",
       "        [-0.4615],\n",
       "        [ 0.0370]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-philip",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-michigan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
