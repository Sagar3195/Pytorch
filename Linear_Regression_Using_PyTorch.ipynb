{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-recovery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "personalized-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        current_sample = self.data[idx, :]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\n",
    "            \"sample\": torch.tensor(current_sample, dtype = torch.float),\n",
    "            \"target\": torch.tensor(current_target, dtype = torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "piano-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "statutory-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rising-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, \n",
    "                                                                      targets, \n",
    "                                                                      stratify = targets\n",
    "                                                                     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dental-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "banned-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 4, num_workers = 0)\n",
    "\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size = 4, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "surprised-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 20)\n",
      "(250, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "chubby-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lambda x, w, b: torch.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "confidential-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.957969337701797\n",
      "1 7.203261010190274\n",
      "2 3.24255100883385\n",
      "3 1.5516151989354414\n",
      "4 0.7853904986318122\n",
      "5 0.427766730860272\n",
      "6 0.2572088811764533\n",
      "7 0.17441914316038898\n",
      "8 0.13361685049343616\n",
      "9 0.113232208950881\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(20,1, requires_grad = True)\n",
    "b = torch.randn(1, requires_grad = True)\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    counter = 0\n",
    "    for data in train_dataloader:\n",
    "        xtrain = data['sample']\n",
    "        ytrain = data['target']\n",
    "        \n",
    "        output = model(xtrain,W, b)\n",
    "        loss = torch.mean((ytrain.view(-1) - output.view(-1))**2)\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            W = W - learning_rate * W.grad\n",
    "            b = b - learning_rate * b.grad\n",
    "            \n",
    "        W.requires_grad_(True)\n",
    "        b.requires_grad_(True)\n",
    "        counter += 1\n",
    "    print(epoch, epoch_loss/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "described-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        xtest = data['sample']\n",
    "        ytest = data['target']\n",
    "        \n",
    "        output = model(xtest, W, b)\n",
    "        labels.append(ytest)\n",
    "        outputs.append(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "forty-nickname",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8477],\n",
       "         [0.2488],\n",
       "         [1.1314],\n",
       "         [0.3537]]),\n",
       " tensor([[ 0.4991],\n",
       "         [ 0.7572],\n",
       "         [-0.3234],\n",
       "         [ 1.0096]]),\n",
       " tensor([[ 0.6324],\n",
       "         [ 0.8027],\n",
       "         [ 0.4970],\n",
       "         [-0.2572]]),\n",
       " tensor([[0.0429],\n",
       "         [0.2980],\n",
       "         [0.9922],\n",
       "         [1.0504]]),\n",
       " tensor([[0.0629],\n",
       "         [0.2364],\n",
       "         [1.5257],\n",
       "         [0.6424]]),\n",
       " tensor([[0.6038],\n",
       "         [1.0340],\n",
       "         [0.8930],\n",
       "         [0.7355]]),\n",
       " tensor([[0.2931],\n",
       "         [0.8750],\n",
       "         [1.1134],\n",
       "         [0.3893]]),\n",
       " tensor([[1.0047],\n",
       "         [0.7066],\n",
       "         [0.7379],\n",
       "         [0.9271]]),\n",
       " tensor([[ 0.9619],\n",
       "         [ 0.7083],\n",
       "         [-0.0244],\n",
       "         [ 0.0498]]),\n",
       " tensor([[-0.1026],\n",
       "         [-0.3664],\n",
       "         [ 0.6292],\n",
       "         [-0.1837]]),\n",
       " tensor([[ 0.0389],\n",
       "         [-0.0076],\n",
       "         [-0.5019],\n",
       "         [ 0.4271]]),\n",
       " tensor([[-0.1978],\n",
       "         [-0.0076],\n",
       "         [ 0.5289],\n",
       "         [ 0.4367]]),\n",
       " tensor([[0.3879],\n",
       "         [0.8487],\n",
       "         [0.8176],\n",
       "         [0.8197]]),\n",
       " tensor([[-0.1123],\n",
       "         [-0.6107],\n",
       "         [ 0.7654],\n",
       "         [-0.2097]]),\n",
       " tensor([[1.1200],\n",
       "         [0.8526],\n",
       "         [0.6533],\n",
       "         [0.3017]]),\n",
       " tensor([[0.5405],\n",
       "         [0.2026],\n",
       "         [0.5159],\n",
       "         [0.5910]]),\n",
       " tensor([[0.7913],\n",
       "         [0.1697],\n",
       "         [0.9694],\n",
       "         [0.4555]]),\n",
       " tensor([[-0.3023],\n",
       "         [ 0.8177],\n",
       "         [ 0.9059],\n",
       "         [-0.1307]]),\n",
       " tensor([[0.5781],\n",
       "         [1.0958],\n",
       "         [0.5068],\n",
       "         [0.9393]]),\n",
       " tensor([[ 1.0495],\n",
       "         [ 0.7333],\n",
       "         [-0.4426],\n",
       "         [ 0.3623]]),\n",
       " tensor([[0.1394],\n",
       "         [0.2017],\n",
       "         [0.4130],\n",
       "         [0.7007]]),\n",
       " tensor([[ 0.3819],\n",
       "         [ 0.5215],\n",
       "         [ 0.9801],\n",
       "         [-0.0898]]),\n",
       " tensor([[-0.3120],\n",
       "         [ 1.0661],\n",
       "         [-0.0188],\n",
       "         [ 0.0726]]),\n",
       " tensor([[0.4514],\n",
       "         [0.0485],\n",
       "         [0.5315],\n",
       "         [1.0456]]),\n",
       " tensor([[0.8476],\n",
       "         [0.3676],\n",
       "         [0.5048],\n",
       "         [0.2601]]),\n",
       " tensor([[0.1069],\n",
       "         [0.8874],\n",
       "         [0.1427],\n",
       "         [0.8704]]),\n",
       " tensor([[ 1.0394],\n",
       "         [ 0.9617],\n",
       "         [ 0.4993],\n",
       "         [-0.3704]]),\n",
       " tensor([[ 0.3806],\n",
       "         [ 0.9492],\n",
       "         [-0.3240],\n",
       "         [ 0.5112]]),\n",
       " tensor([[ 1.0218],\n",
       "         [-0.0564],\n",
       "         [ 0.3418],\n",
       "         [-0.1022]]),\n",
       " tensor([[0.6419],\n",
       "         [0.2014],\n",
       "         [0.1284],\n",
       "         [0.5001]]),\n",
       " tensor([[0.1214],\n",
       "         [0.7613],\n",
       "         [0.1153],\n",
       "         [0.7549]]),\n",
       " tensor([[0.8417],\n",
       "         [0.7878],\n",
       "         [0.1764],\n",
       "         [0.9566]]),\n",
       " tensor([[ 0.8266],\n",
       "         [ 1.0162],\n",
       "         [-0.3044],\n",
       "         [ 0.8267]]),\n",
       " tensor([[0.4418],\n",
       "         [1.1522],\n",
       "         [0.4056],\n",
       "         [0.8404]]),\n",
       " tensor([[0.0456],\n",
       "         [0.3769],\n",
       "         [0.8231],\n",
       "         [0.7779]]),\n",
       " tensor([[ 0.4438],\n",
       "         [ 0.2497],\n",
       "         [-0.2215],\n",
       "         [ 0.8066]]),\n",
       " tensor([[0.5556],\n",
       "         [0.9092],\n",
       "         [0.4694],\n",
       "         [1.2550]]),\n",
       " tensor([[0.7281],\n",
       "         [0.8291],\n",
       "         [0.3431],\n",
       "         [0.3999]]),\n",
       " tensor([[ 0.4969],\n",
       "         [ 0.7063],\n",
       "         [ 0.4694],\n",
       "         [-0.0113]]),\n",
       " tensor([[0.3352],\n",
       "         [0.8658],\n",
       "         [0.5876],\n",
       "         [1.0221]]),\n",
       " tensor([[0.5264],\n",
       "         [0.2114],\n",
       "         [0.8525],\n",
       "         [0.9332]]),\n",
       " tensor([[0.0541],\n",
       "         [0.4953],\n",
       "         [0.5026],\n",
       "         [1.0892]]),\n",
       " tensor([[0.2335],\n",
       "         [0.0572],\n",
       "         [0.3412],\n",
       "         [0.3306]]),\n",
       " tensor([[0.1115],\n",
       "         [0.0717],\n",
       "         [0.2590],\n",
       "         [0.2535]]),\n",
       " tensor([[0.7588],\n",
       "         [0.3534],\n",
       "         [1.0259],\n",
       "         [0.8277]]),\n",
       " tensor([[ 1.0374],\n",
       "         [-0.3421],\n",
       "         [-0.2253],\n",
       "         [ 0.8619]]),\n",
       " tensor([[ 0.9619],\n",
       "         [ 0.6501],\n",
       "         [ 0.9741],\n",
       "         [-0.0329]]),\n",
       " tensor([[0.9359],\n",
       "         [0.4351],\n",
       "         [0.9154],\n",
       "         [0.7810]]),\n",
       " tensor([[0.7720],\n",
       "         [0.4041],\n",
       "         [0.8668],\n",
       "         [0.1068]]),\n",
       " tensor([[0.0398],\n",
       "         [0.1669],\n",
       "         [0.9154],\n",
       "         [1.0051]]),\n",
       " tensor([[ 0.7343],\n",
       "         [-0.0916],\n",
       "         [ 0.3623],\n",
       "         [ 0.9353]]),\n",
       " tensor([[ 0.6027],\n",
       "         [-0.2781],\n",
       "         [ 0.9888],\n",
       "         [ 0.6575]]),\n",
       " tensor([[ 0.4249],\n",
       "         [-0.3956],\n",
       "         [ 0.8457],\n",
       "         [ 0.6365]]),\n",
       " tensor([[ 0.4693],\n",
       "         [-0.2062],\n",
       "         [-0.1506],\n",
       "         [ 0.4475]]),\n",
       " tensor([[1.0676],\n",
       "         [0.4987],\n",
       "         [0.5490],\n",
       "         [0.5148]]),\n",
       " tensor([[0.2333],\n",
       "         [0.8202],\n",
       "         [0.6897],\n",
       "         [0.8586]]),\n",
       " tensor([[0.9006],\n",
       "         [0.3906],\n",
       "         [0.6804],\n",
       "         [0.8531]]),\n",
       " tensor([[ 0.5769],\n",
       "         [ 0.5004],\n",
       "         [-0.0172],\n",
       "         [ 0.1661]]),\n",
       " tensor([[0.0994],\n",
       "         [1.0109],\n",
       "         [1.0117],\n",
       "         [0.1272]]),\n",
       " tensor([[0.3969],\n",
       "         [0.5034],\n",
       "         [0.9159],\n",
       "         [1.2129]]),\n",
       " tensor([[-0.8134],\n",
       "         [ 0.8378],\n",
       "         [ 0.5413],\n",
       "         [-0.2533]]),\n",
       " tensor([[ 0.7935],\n",
       "         [ 0.2953],\n",
       "         [ 0.7333],\n",
       "         [-0.1938]]),\n",
       " tensor([[ 0.7713],\n",
       "         [-0.0679]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "boring-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8477,  0.2488,  1.1314,  0.3537,  0.4991,  0.7572, -0.3234,  1.0096,\n",
       "         0.6324,  0.8027,  0.4970, -0.2572,  0.0429,  0.2980,  0.9922,  1.0504,\n",
       "         0.0629,  0.2364,  1.5257,  0.6424,  0.6038,  1.0340,  0.8930,  0.7355,\n",
       "         0.2931,  0.8750,  1.1134,  0.3893,  1.0047,  0.7066,  0.7379,  0.9271,\n",
       "         0.9619,  0.7083, -0.0244,  0.0498, -0.1026, -0.3664,  0.6292, -0.1837,\n",
       "         0.0389, -0.0076, -0.5019,  0.4271, -0.1978, -0.0076,  0.5289,  0.4367,\n",
       "         0.3879,  0.8487,  0.8176,  0.8197, -0.1123, -0.6107,  0.7654, -0.2097,\n",
       "         1.1200,  0.8526,  0.6533,  0.3017,  0.5405,  0.2026,  0.5159,  0.5910,\n",
       "         0.7913,  0.1697,  0.9694,  0.4555, -0.3023,  0.8177,  0.9059, -0.1307,\n",
       "         0.5781,  1.0958,  0.5068,  0.9393,  1.0495,  0.7333, -0.4426,  0.3623,\n",
       "         0.1394,  0.2017,  0.4130,  0.7007,  0.3819,  0.5215,  0.9801, -0.0898,\n",
       "        -0.3120,  1.0661, -0.0188,  0.0726,  0.4514,  0.0485,  0.5315,  1.0456,\n",
       "         0.8476,  0.3676,  0.5048,  0.2601,  0.1069,  0.8874,  0.1427,  0.8704,\n",
       "         1.0394,  0.9617,  0.4993, -0.3704,  0.3806,  0.9492, -0.3240,  0.5112,\n",
       "         1.0218, -0.0564,  0.3418, -0.1022,  0.6419,  0.2014,  0.1284,  0.5001,\n",
       "         0.1214,  0.7613,  0.1153,  0.7549,  0.8417,  0.7878,  0.1764,  0.9566,\n",
       "         0.8266,  1.0162, -0.3044,  0.8267,  0.4418,  1.1522,  0.4056,  0.8404,\n",
       "         0.0456,  0.3769,  0.8231,  0.7779,  0.4438,  0.2497, -0.2215,  0.8066,\n",
       "         0.5556,  0.9092,  0.4694,  1.2550,  0.7281,  0.8291,  0.3431,  0.3999,\n",
       "         0.4969,  0.7063,  0.4694, -0.0113,  0.3352,  0.8658,  0.5876,  1.0221,\n",
       "         0.5264,  0.2114,  0.8525,  0.9332,  0.0541,  0.4953,  0.5026,  1.0892,\n",
       "         0.2335,  0.0572,  0.3412,  0.3306,  0.1115,  0.0717,  0.2590,  0.2535,\n",
       "         0.7588,  0.3534,  1.0259,  0.8277,  1.0374, -0.3421, -0.2253,  0.8619,\n",
       "         0.9619,  0.6501,  0.9741, -0.0329,  0.9359,  0.4351,  0.9154,  0.7810,\n",
       "         0.7720,  0.4041,  0.8668,  0.1068,  0.0398,  0.1669,  0.9154,  1.0051,\n",
       "         0.7343, -0.0916,  0.3623,  0.9353,  0.6027, -0.2781,  0.9888,  0.6575,\n",
       "         0.4249, -0.3956,  0.8457,  0.6365,  0.4693, -0.2062, -0.1506,  0.4475,\n",
       "         1.0676,  0.4987,  0.5490,  0.5148,  0.2333,  0.8202,  0.6897,  0.8586,\n",
       "         0.9006,  0.3906,  0.6804,  0.8531,  0.5769,  0.5004, -0.0172,  0.1661,\n",
       "         0.0994,  1.0109,  1.0117,  0.1272,  0.3969,  0.5034,  0.9159,  1.2129,\n",
       "        -0.8134,  0.8378,  0.5413, -0.2533,  0.7935,  0.2953,  0.7333, -0.1938,\n",
       "         0.7713, -0.0679])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(outputs).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "proud-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94496"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.roc_auc_score(torch.cat(labels).view(-1), torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-abraham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-moral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
